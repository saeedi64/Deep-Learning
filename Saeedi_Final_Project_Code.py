# -*- coding: utf-8 -*-
"""Midterm_Project_Saeedi_V5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v2XbYMoGllpDgx15y6SqeRuszBJucCD3
"""

#!nvidia-smi

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %tensorflow_version 1.x

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/DL_Midterm_Project

!unzip Cropped_Coin_Mix_Without10deg.zip

#!rm -rf Cropped_Coin

"""#import"""

import argparse
from keras.utils.np_utils import to_categorical
import os
import numpy as np
import scipy.stats as st
import scipy.misc
import time
import sys
import random
from sklearn import metrics
from sklearn.metrics import auc
from copy import copy
#from mixup_generator import MixupGenerator
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.utils import to_categorical
import tensorflow.keras.backend as K  #tensorflow.
from tensorflow.keras.models import load_model #tensorflow.
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import tensorflow.keras.backend as K
from tensorflow.keras import layers
from tensorflow.keras import Model as kmodel
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import Input
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.densenet import DenseNet201
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.python.platform import flags

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import tensorflow as tf
# Undo the inception preprocessing
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

"""#dataset"""

import os
import PIL
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
data_dir="Cropped_Coin_Mix_Without10deg"
images=[]
for i ,filename in enumerate(os.listdir(data_dir)):
         image= Image.open(data_dir+"/"+filename)
         image128= image.resize((128,128),PIL.Image.ANTIALIAS)
         image_arr= np.array(image128)
         images.append(image_arr)
         '''plt.imshow(image)
         plt.show()'''

np.shape(images)

type(images)

# To make images as a numpy.ndarray

images=np.reshape(images, [-1, 128,128,3])

'''0,10,30,45,60,90
   0 1  2  3  4  5'''

labels=[0,0,0,0,0,1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,4,4,4,4,4,
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,
        2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,
        3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,
        4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4]
print(len(labels))
labels=np.asarray(labels , dtype= np.float32)
labels= to_categorical(labels,num_classes=5)
labels

labels.shape

# Normalization

images=images/255.
images = 2 * (images - .5)

#images

"""#train"""

def train_model ( images_train, labels_train, images_test,labels_test,nb_epochs): #, images_val,labels_val , batch_size=32
    # Define TF model graph (for the black-box model).
    x_shape, nb_classes = list(train_images.shape[1:]), train_labels.shape[1]
    print("nb_classes:",nb_classes , "x_shape:",x_shape)
    print("inception v3:")
    input_shape=(128, 128, 3) #train_images[0].shape
    input_tensor = Input(shape=x_shape) #(128, 128, 3)
    print("input_tensor",input_tensor)
    #input_tensor = tf.cast(input_tensor, tf.float32)
    print("input_tensor",input_tensor)
    inception  = InceptionV3(input_shape=input_shape, include_top = False, input_tensor=input_tensor, weights='imagenet')
    for layer in inception.layers:  layer.trainable = True

    inception_last_layer = inception.get_layer('mixed10')
    print('last layer output shape:', inception_last_layer.output_shape)
    inception_last_output = inception_last_layer.output

    #Flatten the output layer to 1 dimension
    x_inception = layers.GlobalMaxPooling2D()(inception_last_output)
    # Add a fully connected layer with 512 hidden units and ReLU activation
    x_inception = layers.Dense(512, activation='relu')(x_inception)
    # Add a dropout rate of 0.7
    x_inception = layers.Dropout(0.5)(x_inception)
    # Add a final sigmoid layer for classification
    x_inception = layers.Dense(nb_classes, activation='softmax')(x_inception)

    # Configure and compile the model

    model = kmodel(input_tensor, x_inception)
 
    #model.summary()   
    

    #report = AccuracyReport()  
    #preds_adv = None

    #Data augmentation
    
    train_datagen = ImageDataGenerator(rotation_range=0, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1 ,shear_range=0.0,
                             horizontal_flip=True,vertical_flip=True,  fill_mode='nearest')
    
    #train_datagen = ImageDataGenerator() 
    #val_datagen = ImageDataGenerator() 
    #train_datagen.fit(images_train)
    #val_datagen.fit(images_val)
    #val_generator= val_datagen.flow(images_val, labels_val ,batch_size=batch_size)

    
    mixup=0
    if mixup:
        from mixup_generator import MixupGenerator
        train_generator = MixupGenerator(images_train, labels_train, batch_size=batch_size, alpha=0.2, datagen=train_datagen)()
    else:
        train_generator=train_datagen.flow(images_train,labels_train)  #, batch_size=batch_size
    
    optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])   #, options = run_opts

   
    print("model.fit_generator:")
    history = model.fit_generator(train_generator,epochs = nb_epochs  # , validation_data =val_generator (images_val, labels_val)
                                ,verbose = 1, shuffle=True) #   , steps_per_epoch=(images_train.shape[0] // batch_size),callbacks=[modelCheck,earlyStop,learning_rate_reduction] 
    model.save("Classifier/model.h5")
    model.save_weights("Classifier/weights.hdf5")
    import pandas as pd
    pd.DataFrame.from_dict(history.history).to_csv('Classifier/history.csv',index=False)

    #evalu(model,batch_size, images_test,labels_test)

    #loss_val, acc_val = model.evaluate(images_val, labels_val, verbose=1)
    loss_test, acc_test = model.evaluate(images_test, labels_test, verbose=1)
    per = model.predict(images_test)  #,batch_size=batch_size
    per=np.argmax(per,-1)
    print("peredictions is:\n", per)
    #print("Validation: accuracy = %f  ;  loss_v = %f" % (acc_val, loss_val))
    print("Test: accuracy = %f  ;  loss = %f" % (acc_test, loss_test)) 
    print("model eval acc:", acc_test)
    print( 'Test accuracy of black-box on legitimate test examples: ' + str(acc_test) )
    labels_t= np.argmax(labels_test,-1)
    print("accuracy_score:",accuracy_score(labels_t, per))
    print(classification_report(labels_t, per))
    from sklearn.metrics import confusion_matrix
    cm = confusion_matrix(labels_t, per)
    print(cm)
    return model,per, acc_test

     
train_images, train_labels, test_images, test_labels = images[25:] , labels[25:]  , images[:25] , labels[:25]  # ,val_images,val_labels
train_model( train_images, train_labels, test_images, test_labels,nb_epochs=100) #, batch_size=50) ,val_images,val_labels

"""#visualize"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# summarize history for accuracy
history= pd.read_csv('Classifier/history.csv')
history

plt.plot(history['loss'])
plt.plot(history['acc'])
plt.title('model cost')
#plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['loss','accuracy'], loc='upper right') #, 'test'
plt.show()

'''plt.plot(history['acc'])
#plt.title('model cost')
plt.ylabel('acc')
plt.xlabel('epoch')
plt.legend(['train'], loc='lower right') #, 'test'
plt.show()'''

